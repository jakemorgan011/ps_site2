<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>horse.beer/dimensionality</title>
    <link rel="stylesheet" href="src/css/style.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"></script>
    <script src="src/lib/dsp.js"></script>
</head>
<body>
    <h1><a href="index.html">horse.beer</a>/dimensionality</h1>
    <div class='content' id='dimensionality'>
        <div class='sidebar'>
            <h2 style="border: wave; font-size: 1.76em;">controls</h2>
            
            <p class='ani-bar' id='p0' style="font-size: 1.35em; margin: 0;">--------</p>
            
            <label for="obj-input">
                <i class="fas fa-upload"></i>upload .obj
            </label>
            <input type="file" id="obj-input" accept=".obj" />
            
            <label for="wav-input">
                <i class="fas fa-upload"></i>upload .wav
            </label>
            <input type="file" id="wav-input" accept=".wav,.mp3" />
            
            <p class='ani-bar' id='p1' style="font-size: 1.35em; margin: 0;">----------</p>
            
            <button id="process-btn" disabled>process audio</button>
            <button id="play-btn" disabled>start playback</button>
            <button id="stop-btn" disabled>stop playback</button>
            
            <p class='ani-bar' id='p2' style="font-size: 1.35em; margin: 0;">----------</p>
            
            <button id="download-btn" disabled>download .wav</button>
            
            <div id="status" style="color: white; padding: 10px; margin-top: 20px;">
                <h3>Status:</h3>
                <p id="status-text">Ready</p>
            </div>
            
            <div id="params-display" style="color: white; padding: 10px; margin-top: 20px; display: none;">
                <h3>Mesh Parameters:</h3>
                <div id="params-list"></div>
            </div>
        </div>
        
        <div class='sketch-container' style="justify-content: center;">
            <div class='canvas-container' id='canvas-container-dimensionality'>
                <script src="src/js/sketch2.js"></script>
            </div>
        </div>
    </div>
    
    <script src="src/js/p_animate.js"></script>
    
    <script>
    class OBJParser {
        static parse(text) {
            const vertices = [];
            const lines = text.split('\n');
            
            for (const line of lines) {
                const parts = line.trim().split(/\s+/);
                if (parts[0] === 'v') {
                    vertices.push({
                        x: parseFloat(parts[1]),
                        y: parseFloat(parts[2]),
                        z: parseFloat(parts[3])
                    });
                }
            }
            
            return vertices;
        }
    }
    
    class MeshFingerprint {
        static calculate(vertices) {
            if (vertices.length === 0) return null;
            
            const byX = [...vertices].sort((a, b) => a.x - b.x);
            const byY = [...vertices].sort((a, b) => a.y - b.y);
            const byZ = [...vertices].sort((a, b) => a.z - b.z);
            
            const xSpread = byX[byX.length - 1].x - byX[0].x;
            const ySpread = byY[byY.length - 1].y - byY[0].y;
            const zSpread = byZ[byZ.length - 1].z - byZ[0].z;
            const volume = xSpread * ySpread * zSpread;
            
            const centerX = vertices.reduce((sum, v) => sum + v.x, 0) / vertices.length;
            const centerY = vertices.reduce((sum, v) => sum + v.y, 0) / vertices.length;
            const centerZ = vertices.reduce((sum, v) => sum + v.z, 0) / vertices.length;
            
            const variance = vertices.reduce((sum, v) => {
                return sum + 
                    Math.pow(v.x - centerX, 2) +
                    Math.pow(v.y - centerY, 2) +
                    Math.pow(v.z - centerZ, 2);
            }, 0) / vertices.length;
            
            // Calculate Y percentiles for spectral destruction zones
            const yPercentiles = [];
            for (let i = 0; i <= 10; i++) {
                const idx = Math.floor((i / 10) * (byY.length - 1));
                yPercentiles.push(byY[idx].y);
            }
            
            const stats = {
                volume: volume,
                xSpread: xSpread,
                ySpread: ySpread,
                zSpread: zSpread,
                centerY: centerY,
                centerZ: centerZ,
                variance: variance,
                yPercentiles: yPercentiles,
                surfaceComplexity: Math.sqrt(variance / (Math.abs(volume) || 1))
            };
            
            return stats;
        }
        
        static mapToAudioParams(stats) {
            const normalize = (value, min, max) => {
                return Math.max(0, Math.min(1, (value - min) / (max - min)));
            };
            
            return {
                // CONTROLLED SPECTRAL PROCESSING
                spectralFreeze: normalize(stats.variance, 0, 10) * 0.4,
                spectralShift: (normalize(stats.centerY, -5, 5) - 0.5) * 0.8,
                spectralCrush: stats.yPercentiles,
                
                // MODERATE CHORUS - 2 voices
                chorusDepth: 0.008 + normalize(stats.xSpread, 0, 10) * 0.022,
                chorusRate: 0.5 + normalize(stats.surfaceComplexity, 0, 3) * 2.5,
                chorusFeedback: normalize(stats.zSpread, 0, 10) * 0.3,
                
                // NOTICEABLE FLANGING
                flangeDepth: 0.002 + normalize(stats.centerZ + 5, 0, 10) * 0.006,
                flangeRate: 0.2 + normalize(stats.surfaceComplexity, 0, 3) * 1.3,
                flangeFeedback: 0.3 + normalize(stats.variance, 0, 10) * 0.3,
                flangeResonance: 3 + normalize(stats.ySpread, 0, 10) * 7,
                
                // BIG REVERB (but not drowning)
                reverbSize: 1.5 + Math.cbrt(Math.abs(stats.volume)) * 3,
                reverbDecay: 0.5 + normalize(Math.abs(stats.volume), 0, 100) * 0.3,
                reverbDiffusion: normalize(stats.surfaceComplexity, 0, 2),
                reverbMix: 0.25 + normalize(Math.abs(stats.volume), 0, 50) * 0.35,
                
                // Keep distortion as-is
                distortionAmount: normalize(stats.variance, 0, 10) * 50,
                
                // Delay for depth
                delayTime: 0.08 + normalize(stats.zSpread, 0, 10) * 0.22,
                delayFeedback: 0.2 + normalize(Math.abs(stats.centerZ), 0, 5) * 0.35
            };
        }
    }
    
    // AGGRESSIVE SPECTRAL DESTRUCTION
    async function spectralDestroy(inputBuffer, params) {
        const sampleRate = inputBuffer.sampleRate;
        const numChannels = inputBuffer.numberOfChannels;
        const outputLength = inputBuffer.length;
        
        const outputChannels = [];
        for (let ch = 0; ch < numChannels; ch++) {
            outputChannels[ch] = new Float32Array(outputLength);
        }
        
        const fftSize = 4096;
        const hopSize = Math.floor(fftSize / 4);
        
        for (let ch = 0; ch < numChannels; ch++) {
            const input = inputBuffer.getChannelData(ch);
            const output = outputChannels[ch];
            const fft = new FFT(fftSize, sampleRate);
            
            let frozenMagnitudes = null;
            
            for (let i = 0; i < input.length - fftSize; i += hopSize) {
                const chunk = input.slice(i, i + fftSize);
                
                const windowed = new Float32Array(fftSize);
                for (let j = 0; j < fftSize; j++) {
                    const w = 0.5 - 0.5 * Math.cos(2 * Math.PI * j / fftSize);
                    windowed[j] = chunk[j] * w;
                }
                
                fft.forward(windowed);
                
                const real = new Float32Array(fft.real);
                const imag = new Float32Array(fft.imag);
                const magnitudes = new Float32Array(real.length);
                const phases = new Float32Array(real.length);
                
                for (let bin = 0; bin < real.length; bin++) {
                    magnitudes[bin] = Math.sqrt(real[bin]**2 + imag[bin]**2);
                    phases[bin] = Math.atan2(imag[bin], real[bin]);
                }
                
                // SPECTRAL FREEZING - hold onto spectral content
                if (!frozenMagnitudes || Math.random() > params.spectralFreeze) {
                    frozenMagnitudes = new Float32Array(magnitudes);
                }
                
                // Blend frozen with current
                for (let bin = 0; bin < magnitudes.length; bin++) {
                    magnitudes[bin] = magnitudes[bin] * (1 - params.spectralFreeze) + 
                                     frozenMagnitudes[bin] * params.spectralFreeze;
                }
                
                // EXTREME FREQUENCY SHIFTING
                if (Math.abs(params.spectralShift) > 0.1) {
                    const newMagnitudes = new Float32Array(magnitudes.length);
                    for (let bin = 0; bin < magnitudes.length; bin++) {
                        const shiftedBin = Math.floor(bin * (1 + params.spectralShift));
                        if (shiftedBin >= 0 && shiftedBin < magnitudes.length) {
                            newMagnitudes[shiftedBin] += magnitudes[bin];
                        }
                    }
                    for (let bin = 0; bin < magnitudes.length; bin++) {
                        magnitudes[bin] = newMagnitudes[bin];
                    }
                }
                
                // SPECTRAL SHAPING - shape frequency zones based on Y-axis
                const numBins = magnitudes.length;
                for (let bin = 0; bin < numBins; bin++) {
                    const percentileIdx = Math.floor((bin / numBins) * (params.spectralCrush.length - 1));
                    const crushAmount = Math.abs(params.spectralCrush[percentileIdx]);
                    
                    // Moderate shaping based on mesh profile
                    if (crushAmount < 0.5) {
                        magnitudes[bin] *= 0.5;
                    } else if (crushAmount > 1.5) {
                        magnitudes[bin] *= 1.8;
                    }
                }
                
                // Convert back
                for (let bin = 0; bin < real.length; bin++) {
                    real[bin] = magnitudes[bin] * Math.cos(phases[bin]);
                    imag[bin] = magnitudes[bin] * Math.sin(phases[bin]);
                }
                
                const processed = fft.inverse(real, imag);
                
                for (let j = 0; j < processed.length; j++) {
                    if (i + j < output.length) {
                        const w = 0.5 - 0.5 * Math.cos(2 * Math.PI * j / fftSize);
                        output[i + j] += processed[j] * w * 0.4;
                    }
                }
            }
        }
        
        return outputChannels;
    }

    class AudioProcessor {
        constructor() {
            this.audioContext = null;
            this.sourceBuffer = null;
            this.processedBuffer = null;
            this.isPlaying = false;
            this.currentSource = null;
        }
        
        async init() {
            this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
        }
        
        async loadAudioFile(file) {
            const arrayBuffer = await file.arrayBuffer();
            this.sourceBuffer = await this.audioContext.decodeAudioData(arrayBuffer);
            return this.sourceBuffer;
        }
        
        async processWithParameters(params) {
            if (!this.sourceBuffer) {
                throw new Error('No audio loaded');
            }

            let processedBuffer = this.sourceBuffer;
            
            // SPECTRAL DESTRUCTION
            const spectralChannels = await spectralDestroy(this.sourceBuffer, params);
            
            processedBuffer = this.audioContext.createBuffer(
                spectralChannels.length,
                spectralChannels[0].length,
                this.sourceBuffer.sampleRate
            );
            
            for (let ch = 0; ch < spectralChannels.length; ch++) {
                processedBuffer.copyToChannel(spectralChannels[ch], ch);
            }
            
            // Build INTENSE DSP chain
            const offlineContext = new OfflineAudioContext(
                processedBuffer.numberOfChannels,
                processedBuffer.length,
                processedBuffer.sampleRate
            );
            
            const source = offlineContext.createBufferSource();
            source.buffer = processedBuffer;
            
            let currentNode = source;
            
            // DISTORTION (kept as-is)
            if (params.distortionAmount > 0) {
                const distortion = offlineContext.createWaveShaper();
                distortion.curve = this.makeDistortionCurve(params.distortionAmount);
                distortion.oversample = '4x';
                currentNode.connect(distortion);
                currentNode = distortion;
            }
            
            // MODERATE CHORUS - 2 voices for clarity
            const chorus1 = offlineContext.createDelay(0.1);
            const chorus2 = offlineContext.createDelay(0.1);
            
            chorus1.delayTime.value = 0.015 + params.chorusDepth;
            chorus2.delayTime.value = 0.028 + params.chorusDepth * 1.4;
            
            const chorusFeedback = offlineContext.createGain();
            chorusFeedback.gain.value = params.chorusFeedback;
            
            const chorusMix = offlineContext.createGain();
            chorusMix.gain.value = 0.5;
            
            currentNode.connect(chorus1);
            currentNode.connect(chorus2);
            
            chorus1.connect(chorusMix);
            chorus2.connect(chorusMix);
            
            chorusMix.connect(chorusFeedback);
            chorusFeedback.connect(chorus1);
            
            // NOTICEABLE FLANGING
            const flanger = offlineContext.createDelay(0.015);
            flanger.delayTime.value = 0.001 + params.flangeDepth;
            
            const flangeFilter = offlineContext.createBiquadFilter();
            flangeFilter.type = 'bandpass';
            flangeFilter.frequency.value = 1000;
            flangeFilter.Q.value = params.flangeResonance;
            
            const flangeFeedback = offlineContext.createGain();
            flangeFeedback.gain.value = params.flangeFeedback;
            
            const flangeMix = offlineContext.createGain();
            flangeMix.gain.value = 0.5;
            
            currentNode.connect(flanger);
            chorusMix.connect(flanger);
            
            flanger.connect(flangeFilter);
            flangeFilter.connect(flangeFeedback);
            flangeFeedback.connect(flanger);
            flangeFilter.connect(flangeMix);
            
            // DELAY FOR DEPTH
            const delay = offlineContext.createDelay(1.0);
            const delayFeedback = offlineContext.createGain();
            const delayMix = offlineContext.createGain();
            
            delay.delayTime.value = params.delayTime;
            delayFeedback.gain.value = params.delayFeedback;
            delayMix.gain.value = 0.25;
            
            currentNode.connect(delay);
            chorusMix.connect(delay);
            flangeMix.connect(delay);
            
            delay.connect(delayFeedback);
            delayFeedback.connect(delay);
            delay.connect(delayMix);
            
            // BIG REVERB
            const convolver = offlineContext.createConvolver();
            convolver.buffer = this.createBigReverb(
                offlineContext.sampleRate,
                params.reverbSize,
                params.reverbDecay,
                params.reverbDiffusion
            );
            
            const reverbMix = offlineContext.createGain();
            reverbMix.gain.value = params.reverbMix;
            
            currentNode.connect(convolver);
            chorusMix.connect(convolver);
            flangeMix.connect(convolver);
            delayMix.connect(convolver);
            
            convolver.connect(reverbMix);
            
            // DRY SIGNAL
            const dryGain = offlineContext.createGain();
            dryGain.gain.value = 0.6;
            
            currentNode.connect(dryGain);
            chorusMix.connect(dryGain);
            
            // MASTER OUT
            const masterGain = offlineContext.createGain();
            masterGain.gain.value = 0.95;
            
            dryGain.connect(masterGain);
            flangeMix.connect(masterGain);
            delayMix.connect(masterGain);
            reverbMix.connect(masterGain);
            
            masterGain.connect(offlineContext.destination);

            source.start(0);
            
            this.processedBuffer = await offlineContext.startRendering();
            return this.processedBuffer;
        }
        
        makeDistortionCurve(amount) {
            const samples = 44100;
            const curve = new Float32Array(samples);
            const deg = Math.PI / 180;
            
            for (let i = 0; i < samples; i++) {
                const x = (i * 2) / samples - 1;
                curve[i] = ((3 + amount) * x * 20 * deg) / (Math.PI + amount * Math.abs(x));
            }
            
            return curve;
        }
        
        createBigReverb(sampleRate, size, decay, diffusion) {
            const duration = Math.max(1, size);
            const length = Math.floor(sampleRate * duration);
            const impulse = new Float32Array(length);
            
            // Create rich, diffuse reverb
            for (let i = 0; i < length; i++) {
                const t = i / length;
                const envelope = Math.pow(1 - t, decay * 2.5);
                
                let sample = 0;
                const reflections = Math.floor(15 + diffusion * 40);
                
                for (let r = 0; r < reflections; r++) {
                    const reflectionTime = (r / reflections) * length;
                    if (i > reflectionTime) {
                        const reflection = (Math.random() * 2 - 1) * Math.exp(-r * 0.08);
                        sample += reflection;
                    }
                }
                
                // Add late reflections
                if (t > 0.3) {
                    sample += (Math.random() * 2 - 1) * Math.pow(1 - t, decay * 4) * 0.8;
                }
                
                impulse[i] = sample * envelope;
            }
            
            return this.audioContext.createBuffer(1, length, sampleRate);
        }
        
        play(buffer) {
            if (this.isPlaying) this.stop();
            
            this.currentSource = this.audioContext.createBufferSource();
            this.currentSource.buffer = buffer || this.processedBuffer;
            this.currentSource.connect(this.audioContext.destination);
            this.currentSource.start(0);
            this.isPlaying = true;
            
            this.currentSource.onended = () => {
                this.isPlaying = false;
            };
        }
        
        stop() {
            if (this.currentSource) {
                this.currentSource.stop();
                this.currentSource = null;
                this.isPlaying = false;
            }
        }
        
        downloadProcessedAudio(filename = 'processed.wav') {
            if (!this.processedBuffer) {
                throw new Error('No processed audio available');
            }
            
            const wav = this.audioBufferToWav(this.processedBuffer);
            const blob = new Blob([wav], { type: 'audio/wav' });
            const url = URL.createObjectURL(blob);
            
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            a.click();
            
            URL.revokeObjectURL(url);
        }
        
        audioBufferToWav(buffer) {
            const numChannels = buffer.numberOfChannels;
            const sampleRate = buffer.sampleRate;
            const format = 1;
            const bitDepth = 16;
            
            const bytesPerSample = bitDepth / 8;
            const blockAlign = numChannels * bytesPerSample;
            
            const data = [];
            for (let i = 0; i < buffer.numberOfChannels; i++) {
                data.push(buffer.getChannelData(i));
            }
            
            const length = data[0].length;
            const arrayBuffer = new ArrayBuffer(44 + length * blockAlign);
            const view = new DataView(arrayBuffer);
            
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * blockAlign, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, format, true);
            view.setUint16(22, numChannels, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * blockAlign, true);
            view.setUint16(32, blockAlign, true);
            view.setUint16(34, bitDepth, true);
            writeString(36, 'data');
            view.setUint32(40, length * blockAlign, true);
            
            let offset = 44;
            for (let i = 0; i < length; i++) {
                for (let channel = 0; channel < numChannels; channel++) {
                    const sample = Math.max(-1, Math.min(1, data[channel][i]));
                    view.setInt16(offset, sample * 0x7FFF, true);
                    offset += 2;
                }
            }
            
            return arrayBuffer;
        }
    }
    
    const audioProcessor = new AudioProcessor();
    let meshFingerprint = null;
    let audioParams = null;
    
    document.addEventListener('click', () => {
        if (!audioProcessor.audioContext) {
            audioProcessor.init();
        }
    }, { once: true });
    
    document.getElementById('obj-input').addEventListener('change', async (e) => {
        const file = e.target.files[0];
        if (file) {
            const text = await file.text();
            const vertices = OBJParser.parse(text);
            
            document.getElementById('status-text').textContent = `Loaded ${vertices.length} vertices`;
            
            meshFingerprint = MeshFingerprint.calculate(vertices);
            audioParams = MeshFingerprint.mapToAudioParams(meshFingerprint);
            
            const paramsDisplay = document.getElementById('params-display');
            const paramsList = document.getElementById('params-list');
            paramsDisplay.style.display = 'block';
            
            paramsList.innerHTML = Object.entries(audioParams)
                .filter(([key]) => key !== 'spectralCrush')
                .map(([key, value]) => `<p>${key}: ${typeof value === 'number' ? value.toFixed(3) : value}</p>`)
                .join('');
            
            if (audioProcessor.sourceBuffer) {
                document.getElementById('process-btn').disabled = false;
            }
        }
    });
    
    document.getElementById('wav-input').addEventListener('change', async (e) => {
        const file = e.target.files[0];
        if (file) {
            await audioProcessor.init();
            await audioProcessor.loadAudioFile(file);
            
            document.getElementById('status-text').textContent = 'Audio loaded';
            
            if (audioParams) {
                document.getElementById('process-btn').disabled = false;
            }
        }
    });
    
    document.getElementById('process-btn').addEventListener('click', async () => {
        if (audioParams && audioProcessor.sourceBuffer) {
            document.getElementById('status-text').textContent = 'Processing...';
            
            try {
                await audioProcessor.processWithParameters(audioParams);
                
                document.getElementById('status-text').textContent = 'Processing complete!';
                document.getElementById('play-btn').disabled = false;
                document.getElementById('download-btn').disabled = false;
            } catch (error) {
                document.getElementById('status-text').textContent = `Error: ${error.message}`;
            }
        }
    });
    
    document.getElementById('play-btn').addEventListener('click', () => {
        audioProcessor.play();
        document.getElementById('stop-btn').disabled = false;
    });
    
    document.getElementById('stop-btn').addEventListener('click', () => {
        audioProcessor.stop();
        document.getElementById('stop-btn').disabled = true;
    });
    
    document.getElementById('download-btn').addEventListener('click', () => {
        audioProcessor.downloadProcessedAudio('dimensionality-processed.wav');
    });
    </script>
</body>
</html>
